################################################################################
# PromptForge High Availability Docker Compose Configuration
################################################################################
#
# This configuration sets up a high availability deployment with:
#   - Multiple backend instances (3x)
#   - Multiple frontend instances (2x)
#   - PostgreSQL with replication support
#   - Redis Sentinel for HA
#   - Nginx load balancer
#
# Usage:
#   docker-compose -f docker-compose.ha.yml up -d
#
################################################################################

version: '3.8'

services:
  #-----------------------------------------------------------------------------
  # PostgreSQL Primary (Master)
  #-----------------------------------------------------------------------------
  postgres-primary:
    image: postgres:14-alpine
    container_name: promptforge-postgres-primary
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-promptforge}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-promptforge_prod}
      # Replication settings
      POSTGRES_REPLICATION_USER: ${POSTGRES_REPLICATION_USER:-replicator}
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    volumes:
      - postgres_primary_data:/var/lib/postgresql/data
      - ./ha/postgresql/primary/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./ha/postgresql/primary/pg_hba.conf:/etc/postgresql/pg_hba.conf
      - ./ha/postgresql/init:/docker-entrypoint-initdb.d
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    ports:
      - "5432:5432"
    networks:
      ha_network:
        ipv4_address: 172.26.0.10
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-promptforge}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  #-----------------------------------------------------------------------------
  # PostgreSQL Replica (Standby)
  #-----------------------------------------------------------------------------
  postgres-replica:
    image: postgres:14-alpine
    container_name: promptforge-postgres-replica
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-promptforge}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-promptforge_prod}
      POSTGRES_PRIMARY_HOST: postgres-primary
      POSTGRES_PRIMARY_PORT: 5432
      POSTGRES_REPLICATION_USER: ${POSTGRES_REPLICATION_USER:-replicator}
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
      - ./ha/postgresql/replica/setup-replica.sh:/docker-entrypoint-initdb.d/setup-replica.sh
    command: postgres
    ports:
      - "5433:5432"
    networks:
      ha_network:
        ipv4_address: 172.26.0.11
    depends_on:
      - postgres-primary
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-promptforge}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G

  #-----------------------------------------------------------------------------
  # Redis Master
  #-----------------------------------------------------------------------------
  redis-master:
    image: redis:7-alpine
    container_name: promptforge-redis-master
    restart: unless-stopped
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
    volumes:
      - redis_master_data:/data
    ports:
      - "6379:6379"
    networks:
      ha_network:
        ipv4_address: 172.26.0.20
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

  #-----------------------------------------------------------------------------
  # Redis Replica
  #-----------------------------------------------------------------------------
  redis-replica:
    image: redis:7-alpine
    container_name: promptforge-redis-replica
    restart: unless-stopped
    command: >
      redis-server
      --slaveof redis-master 6379
      --masterauth ${REDIS_PASSWORD}
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
    volumes:
      - redis_replica_data:/data
    ports:
      - "6380:6379"
    networks:
      ha_network:
        ipv4_address: 172.26.0.21
    depends_on:
      - redis-master
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

  #-----------------------------------------------------------------------------
  # Redis Sentinel (3 instances for quorum)
  #-----------------------------------------------------------------------------
  redis-sentinel-1:
    image: redis:7-alpine
    container_name: promptforge-redis-sentinel-1
    restart: unless-stopped
    command: redis-sentinel /etc/redis/sentinel.conf
    volumes:
      - ./ha/redis/sentinel.conf:/etc/redis/sentinel.conf
      - redis_sentinel_1_data:/data
    ports:
      - "26379:26379"
    networks:
      ha_network:
        ipv4_address: 172.26.0.25
    depends_on:
      - redis-master
      - redis-replica
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  redis-sentinel-2:
    image: redis:7-alpine
    container_name: promptforge-redis-sentinel-2
    restart: unless-stopped
    command: redis-sentinel /etc/redis/sentinel.conf
    volumes:
      - ./ha/redis/sentinel.conf:/etc/redis/sentinel.conf
      - redis_sentinel_2_data:/data
    ports:
      - "26380:26379"
    networks:
      ha_network:
        ipv4_address: 172.26.0.26
    depends_on:
      - redis-master
      - redis-replica
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  redis-sentinel-3:
    image: redis:7-alpine
    container_name: promptforge-redis-sentinel-3
    restart: unless-stopped
    command: redis-sentinel /etc/redis/sentinel.conf
    volumes:
      - ./ha/redis/sentinel.conf:/etc/redis/sentinel.conf
      - redis_sentinel_3_data:/data
    ports:
      - "26381:26379"
    networks:
      ha_network:
        ipv4_address: 172.26.0.27
    depends_on:
      - redis-master
      - redis-replica
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  #-----------------------------------------------------------------------------
  # Backend Instances (3x for load balancing)
  #-----------------------------------------------------------------------------
  backend1:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: promptforge-backend-1
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-promptforge}:${POSTGRES_PASSWORD}@postgres-primary:5432/${POSTGRES_DB:-promptforge_prod}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis-master:6379/0
      REDIS_SENTINEL_HOSTS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_SENTINEL_MASTER: mymaster
      SECRET_KEY: ${SECRET_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      WORKERS: ${BACKEND_WORKERS:-2}
      ENVIRONMENT: production
    volumes:
      - ./logs/backend1:/app/logs
    networks:
      - ha_network
    depends_on:
      postgres-primary:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 512M

  backend2:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: promptforge-backend-2
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-promptforge}:${POSTGRES_PASSWORD}@postgres-primary:5432/${POSTGRES_DB:-promptforge_prod}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis-master:6379/0
      REDIS_SENTINEL_HOSTS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_SENTINEL_MASTER: mymaster
      SECRET_KEY: ${SECRET_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      WORKERS: ${BACKEND_WORKERS:-2}
      ENVIRONMENT: production
    volumes:
      - ./logs/backend2:/app/logs
    networks:
      - ha_network
    depends_on:
      postgres-primary:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 512M

  backend3:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: promptforge-backend-3
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-promptforge}:${POSTGRES_PASSWORD}@postgres-primary:5432/${POSTGRES_DB:-promptforge_prod}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis-master:6379/0
      REDIS_SENTINEL_HOSTS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_SENTINEL_MASTER: mymaster
      SECRET_KEY: ${SECRET_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      WORKERS: ${BACKEND_WORKERS:-2}
      ENVIRONMENT: production
    volumes:
      - ./logs/backend3:/app/logs
    networks:
      - ha_network
    depends_on:
      postgres-primary:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 512M

  #-----------------------------------------------------------------------------
  # Frontend Instances (2x for redundancy)
  #-----------------------------------------------------------------------------
  frontend1:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
      args:
        VITE_API_URL: ${VITE_API_URL}
    container_name: promptforge-frontend-1
    restart: unless-stopped
    networks:
      - ha_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  frontend2:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
      args:
        VITE_API_URL: ${VITE_API_URL}
    container_name: promptforge-frontend-2
    restart: unless-stopped
    networks:
      - ha_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  #-----------------------------------------------------------------------------
  # Nginx Load Balancer
  #-----------------------------------------------------------------------------
  nginx:
    image: nginx:alpine
    container_name: promptforge-nginx-lb
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # Status page (internal only)
    volumes:
      - ./ha/nginx/load-balancer.conf:/etc/nginx/conf.d/default.conf
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
      - ./nginx/certbot:/var/www/certbot:ro
    networks:
      - ha_network
    depends_on:
      - backend1
      - backend2
      - backend3
      - frontend1
      - frontend2
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

#-----------------------------------------------------------------------------
# Networks
#-----------------------------------------------------------------------------
networks:
  ha_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.26.0.0/16
          gateway: 172.26.0.1

#-----------------------------------------------------------------------------
# Volumes
#-----------------------------------------------------------------------------
volumes:
  postgres_primary_data:
    driver: local
  postgres_replica_data:
    driver: local
  redis_master_data:
    driver: local
  redis_replica_data:
    driver: local
  redis_sentinel_1_data:
    driver: local
  redis_sentinel_2_data:
    driver: local
  redis_sentinel_3_data:
    driver: local

################################################################################
# High Availability Configuration Notes
################################################################################
#
# Architecture:
#   - 3 backend instances behind load balancer
#   - 2 frontend instances for redundancy
#   - PostgreSQL primary + replica
#   - Redis master + replica + 3 Sentinels
#   - Nginx load balancer with health checks
#
# Failover:
#   - Backend: Automatic via Nginx (proxy_next_upstream)
#   - PostgreSQL: Manual or with pg_auto_failover/Patroni
#   - Redis: Automatic via Sentinel (quorum-based)
#
# Scaling:
#   - Add more backend/frontend instances to docker-compose
#   - Update Nginx upstream configuration
#   - Restart nginx: docker-compose restart nginx
#
# Monitoring:
#   - Nginx status: http://localhost:8080/nginx_status
#   - Health checks via /health endpoints
#   - Container health via docker ps
#
################################################################################
